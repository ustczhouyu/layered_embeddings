{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask R-CNN - Train on Shapes Dataset\n",
    "\n",
    "\n",
    "This notebook shows how to train Mask R-CNN on your own dataset. To keep things simple we use a synthetic dataset of shapes (squares, triangles, and circles) which enables fast training. You'd still need a GPU, though, because the network backbone is a Resnet101, which would be too slow to train on a CPU. On a GPU, you can start to get okay-ish results in a few minutes, and good results in less than an hour.\n",
    "\n",
    "The code of the *Shapes* dataset is included below. It generates images on the fly, so it doesn't require downloading any data. And it can generate images of any size, so we pick a small image size to train faster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "sys.path.append('C:/Users/yliu60/Documents/GitHub/amodalAPI/PythonAPI/pycocotools')\n",
    "sys.path.append('C:/Users/Yanfeng Liu/Documents/GitHub/amodalAPI/PythonAPI/pycocotools')\n",
    "\n",
    "import mask as Mask\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../../\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn.model import log\n",
    "from mrcnn import utils\n",
    "from mrcnn import visualize\n",
    "from PIL import Image, ImageDraw\n",
    "import mrcnn_shapes as shapes_lib\n",
    "import mrcnn.model as modellib\n",
    "%matplotlib inline \n",
    "\n",
    "import metrics_hist\n",
    "import params as params_lib\n",
    "import batchEval\n",
    "from experiment import get_mrcnn_result_list\n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)\n",
    "\n",
    "from importlib import reload\n",
    "_ = reload(shapes_lib)\n",
    "_ = reload(visualize)\n",
    "_ = reload(modellib)\n",
    "_ = reload(metrics_hist)\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# The GPU id to use\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_instances_per_class = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     2\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DATASET_NAME                   shapes\n",
      "DATASET_TYPE                   val\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "DOWNSAMPLE_FACTOR              4\n",
      "DOWNSAMPLE_RESOLUTION          64\n",
      "DT_DIR                         C:/Users/yliu60/Documents/GitHub/Pixel-Embedding/results/mrcnn/12-1_2_3/\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "FULL_GT                        True\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 2\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  256\n",
      "IMAGE_META_SIZE                16\n",
      "IMAGE_MIN_DIM                  256\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              none\n",
      "IMAGE_SHAPE                    [256 256   3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.0001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           shapes\n",
      "NUM_CLASSES                    4\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "RANDOM                         False\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "SMALL                          True\n",
      "STEPS_PER_EPOCH                1000\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           64\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               100\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class ShapesConfig(Config):\n",
    "    \"\"\"Configuration for training on the toy shapes dataset.\n",
    "    Derives from the base Config class and overrides values specific\n",
    "    to the toy shapes dataset.\n",
    "    \"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"shapes\"\n",
    "\n",
    "    # Train on 1 GPU and 8 images per GPU. We can put multiple images on each\n",
    "    # GPU because the images are small. Batch size is 8 (GPUs * images/GPU).\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 2\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 3  # background + 3 shapes\n",
    "\n",
    "    # Use small images for faster training. Set the limits of the small side\n",
    "    # the large side, and that determines the image shape.\n",
    "    IMAGE_MIN_DIM = 256\n",
    "    IMAGE_MAX_DIM = 256\n",
    "    \n",
    "    IMAGE_RESIZE_MODE = \"none\"\n",
    "\n",
    "    # Use smaller anchors because our image and objects are small\n",
    "    RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)  # anchor side in pixels\n",
    "\n",
    "    # Reduce training ROIs per image because the images are small and have\n",
    "    # few objects. Aim to allow ROI sampling to pick 33% positive ROIs.\n",
    "    TRAIN_ROIS_PER_IMAGE = 64\n",
    "\n",
    "    # Use a small epoch since the data is simple\n",
    "    STEPS_PER_EPOCH = 1000\n",
    "\n",
    "    # use small validation steps since the epoch is small\n",
    "    VALIDATION_STEPS = 100\n",
    "    \n",
    "    LEARNING_RATE = 1e-4\n",
    "    \n",
    "    # custom properties\n",
    "    FULL_GT = True\n",
    "    SMALL = True\n",
    "    RANDOM = False\n",
    "    DATASET_TYPE = 'val'\n",
    "    DATASET_NAME = 'shapes'\n",
    "    DT_DIR = 'C:/Users/yliu60/Documents/GitHub/Pixel-Embedding/results/mrcnn/12-1_2_3/'\n",
    "    DOWNSAMPLE_FACTOR = 4\n",
    "    DOWNSAMPLE_RESOLUTION = 64\n",
    "    \n",
    "config = ShapesConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(num_instances_per_class)\n",
    "# Validation dataset\n",
    "dataset_val = shapes_lib.ShapesDataset(num_instances_per_class)\n",
    "dataset_val.load_shapes(1000, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])\n",
    "dataset_val.prepare()\n",
    "config.MRCNN_DATASET = dataset_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=8):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Change the default size attribute to control the size\n",
    "    of rendered images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceConfig(ShapesConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "inference_config = InferenceConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model in training mode\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                          model_dir=MODEL_DIR)\n",
    "\n",
    "# Which weights to start with?\n",
    "init_with = \"last\"  # imagenet, coco, or last\n",
    "\n",
    "if init_with == \"imagenet\":\n",
    "    model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
    "elif init_with == \"coco\":\n",
    "    # Load weights trained on MS COCO, but skip layers that\n",
    "    # are different due to the different number of classes\n",
    "    # See README for instructions to download the COCO weights\n",
    "    model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
    "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "elif init_with == \"last\":\n",
    "    # Load the last model you trained and continue training\n",
    "    model.load_weights('C:/Users/yliu60/Documents/GitHub/Pixel-Embedding/logs/shapes_12_instances_84_epoch.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "hist = metrics_hist.MetricsHist(config.DT_DIR)\n",
    "# get new training dataset at every epoch\n",
    "dataset_train = shapes_lib.ShapesDataset(num_instances_per_class)\n",
    "dataset_train.load_shapes(1, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])\n",
    "dataset_train.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting at epoch 84. LR=0.0001\n",
      "\n",
      "Checkpoint Path: C:\\Users\\yliu60\\Documents\\GitHub\\Pixel-Embedding\\logs\\shapes20190303T1929\\mask_rcnn_shapes_0.h5\n",
      "Selecting layers to train\n",
      "Epoch 85/100\n",
      "1000/1000 [==============================] - 907s 907ms/step - loss: 0.9597 - rpn_class_loss: 0.0061 - rpn_bbox_loss: 0.2512 - mrcnn_class_loss: 0.3293 - mrcnn_bbox_loss: 0.1648 - mrcnn_mask_loss: 0.2083 - val_loss: 0.9696 - val_rpn_class_loss: 0.0065 - val_rpn_bbox_loss: 0.2621 - val_mrcnn_class_loss: 0.3284 - val_mrcnn_bbox_loss: 0.1641 - val_mrcnn_mask_loss: 0.2085\n",
      "Epoch 86/100\n",
      "1000/1000 [==============================] - 855s 855ms/step - loss: 0.9700 - rpn_class_loss: 0.0062 - rpn_bbox_loss: 0.2515 - mrcnn_class_loss: 0.3344 - mrcnn_bbox_loss: 0.1675 - mrcnn_mask_loss: 0.2105 - val_loss: 0.9746 - val_rpn_class_loss: 0.0071 - val_rpn_bbox_loss: 0.2704 - val_mrcnn_class_loss: 0.3290 - val_mrcnn_bbox_loss: 0.1671 - val_mrcnn_mask_loss: 0.2011\n",
      "Epoch 87/100\n",
      "1000/1000 [==============================] - 863s 863ms/step - loss: 0.9555 - rpn_class_loss: 0.0064 - rpn_bbox_loss: 0.2546 - mrcnn_class_loss: 0.3251 - mrcnn_bbox_loss: 0.1621 - mrcnn_mask_loss: 0.2073 - val_loss: 1.0088 - val_rpn_class_loss: 0.0073 - val_rpn_bbox_loss: 0.2637 - val_mrcnn_class_loss: 0.3470 - val_mrcnn_bbox_loss: 0.1741 - val_mrcnn_mask_loss: 0.2168\n",
      "Epoch 88/100\n",
      "1000/1000 [==============================] - 866s 866ms/step - loss: 0.9767 - rpn_class_loss: 0.0060 - rpn_bbox_loss: 0.2635 - mrcnn_class_loss: 0.3309 - mrcnn_bbox_loss: 0.1670 - mrcnn_mask_loss: 0.2092 - val_loss: 0.9714 - val_rpn_class_loss: 0.0069 - val_rpn_bbox_loss: 0.2579 - val_mrcnn_class_loss: 0.3301 - val_mrcnn_bbox_loss: 0.1649 - val_mrcnn_mask_loss: 0.2117\n",
      "Epoch 89/100\n",
      "1000/1000 [==============================] - 864s 864ms/step - loss: 0.9488 - rpn_class_loss: 0.0064 - rpn_bbox_loss: 0.2511 - mrcnn_class_loss: 0.3215 - mrcnn_bbox_loss: 0.1636 - mrcnn_mask_loss: 0.2062 - val_loss: 0.9860 - val_rpn_class_loss: 0.0068 - val_rpn_bbox_loss: 0.2769 - val_mrcnn_class_loss: 0.3261 - val_mrcnn_bbox_loss: 0.1647 - val_mrcnn_mask_loss: 0.2115\n",
      "Epoch 90/100\n",
      "1000/1000 [==============================] - 866s 866ms/step - loss: 0.9753 - rpn_class_loss: 0.0069 - rpn_bbox_loss: 0.2650 - mrcnn_class_loss: 0.3292 - mrcnn_bbox_loss: 0.1657 - mrcnn_mask_loss: 0.2085 - val_loss: 0.9980 - val_rpn_class_loss: 0.0063 - val_rpn_bbox_loss: 0.2598 - val_mrcnn_class_loss: 0.3436 - val_mrcnn_bbox_loss: 0.1763 - val_mrcnn_mask_loss: 0.2121\n",
      "Epoch 91/100\n",
      "1000/1000 [==============================] - 868s 868ms/step - loss: 0.9860 - rpn_class_loss: 0.0065 - rpn_bbox_loss: 0.2702 - mrcnn_class_loss: 0.3309 - mrcnn_bbox_loss: 0.1689 - mrcnn_mask_loss: 0.2094 - val_loss: 1.0118 - val_rpn_class_loss: 0.0062 - val_rpn_bbox_loss: 0.2805 - val_mrcnn_class_loss: 0.3379 - val_mrcnn_bbox_loss: 0.1756 - val_mrcnn_mask_loss: 0.2115\n",
      "Epoch 92/100\n",
      "1000/1000 [==============================] - 869s 869ms/step - loss: 0.9916 - rpn_class_loss: 0.0068 - rpn_bbox_loss: 0.2677 - mrcnn_class_loss: 0.3371 - mrcnn_bbox_loss: 0.1711 - mrcnn_mask_loss: 0.2089 - val_loss: 1.0186 - val_rpn_class_loss: 0.0076 - val_rpn_bbox_loss: 0.2806 - val_mrcnn_class_loss: 0.3474 - val_mrcnn_bbox_loss: 0.1697 - val_mrcnn_mask_loss: 0.2132\n",
      "Epoch 93/100\n",
      "1000/1000 [==============================] - 868s 868ms/step - loss: 0.9862 - rpn_class_loss: 0.0066 - rpn_bbox_loss: 0.2687 - mrcnn_class_loss: 0.3344 - mrcnn_bbox_loss: 0.1675 - mrcnn_mask_loss: 0.2090 - val_loss: 1.0057 - val_rpn_class_loss: 0.0070 - val_rpn_bbox_loss: 0.2809 - val_mrcnn_class_loss: 0.3359 - val_mrcnn_bbox_loss: 0.1699 - val_mrcnn_mask_loss: 0.2119\n",
      "Epoch 94/100\n",
      "1000/1000 [==============================] - 873s 873ms/step - loss: 0.9983 - rpn_class_loss: 0.0067 - rpn_bbox_loss: 0.2712 - mrcnn_class_loss: 0.3386 - mrcnn_bbox_loss: 0.1702 - mrcnn_mask_loss: 0.2115 - val_loss: 1.0227 - val_rpn_class_loss: 0.0069 - val_rpn_bbox_loss: 0.2875 - val_mrcnn_class_loss: 0.3364 - val_mrcnn_bbox_loss: 0.1750 - val_mrcnn_mask_loss: 0.2169\n",
      "Epoch 95/100\n",
      "1000/1000 [==============================] - 877s 877ms/step - loss: 0.9912 - rpn_class_loss: 0.0068 - rpn_bbox_loss: 0.2689 - mrcnn_class_loss: 0.3349 - mrcnn_bbox_loss: 0.1709 - mrcnn_mask_loss: 0.2096 - val_loss: 0.9694 - val_rpn_class_loss: 0.0065 - val_rpn_bbox_loss: 0.2612 - val_mrcnn_class_loss: 0.3312 - val_mrcnn_bbox_loss: 0.1672 - val_mrcnn_mask_loss: 0.2033\n",
      "Epoch 96/100\n",
      "1000/1000 [==============================] - 874s 874ms/step - loss: 0.9847 - rpn_class_loss: 0.0064 - rpn_bbox_loss: 0.2627 - mrcnn_class_loss: 0.3352 - mrcnn_bbox_loss: 0.1698 - mrcnn_mask_loss: 0.2106 - val_loss: 1.0100 - val_rpn_class_loss: 0.0064 - val_rpn_bbox_loss: 0.2780 - val_mrcnn_class_loss: 0.3392 - val_mrcnn_bbox_loss: 0.1720 - val_mrcnn_mask_loss: 0.2144\n",
      "Epoch 97/100\n",
      "1000/1000 [==============================] - 874s 874ms/step - loss: 0.9814 - rpn_class_loss: 0.0063 - rpn_bbox_loss: 0.2637 - mrcnn_class_loss: 0.3344 - mrcnn_bbox_loss: 0.1682 - mrcnn_mask_loss: 0.2088 - val_loss: 0.9669 - val_rpn_class_loss: 0.0054 - val_rpn_bbox_loss: 0.2546 - val_mrcnn_class_loss: 0.3352 - val_mrcnn_bbox_loss: 0.1651 - val_mrcnn_mask_loss: 0.2064\n",
      "Epoch 98/100\n",
      "1000/1000 [==============================] - 872s 872ms/step - loss: 0.9746 - rpn_class_loss: 0.0060 - rpn_bbox_loss: 0.2621 - mrcnn_class_loss: 0.3334 - mrcnn_bbox_loss: 0.1660 - mrcnn_mask_loss: 0.2071 - val_loss: 0.9703 - val_rpn_class_loss: 0.0058 - val_rpn_bbox_loss: 0.2576 - val_mrcnn_class_loss: 0.3353 - val_mrcnn_bbox_loss: 0.1665 - val_mrcnn_mask_loss: 0.2049\n",
      "Epoch 99/100\n",
      "1000/1000 [==============================] - 876s 876ms/step - loss: 0.9840 - rpn_class_loss: 0.0066 - rpn_bbox_loss: 0.2671 - mrcnn_class_loss: 0.3351 - mrcnn_bbox_loss: 0.1665 - mrcnn_mask_loss: 0.2087 - val_loss: 1.0146 - val_rpn_class_loss: 0.0078 - val_rpn_bbox_loss: 0.2928 - val_mrcnn_class_loss: 0.3311 - val_mrcnn_bbox_loss: 0.1747 - val_mrcnn_mask_loss: 0.2082\n",
      "Epoch 100/100\n",
      "1000/1000 [==============================] - 880s 880ms/step - loss: 0.9595 - rpn_class_loss: 0.0066 - rpn_bbox_loss: 0.2613 - mrcnn_class_loss: 0.3240 - mrcnn_bbox_loss: 0.1634 - mrcnn_mask_loss: 0.2042 - val_loss: 0.9544 - val_rpn_class_loss: 0.0062 - val_rpn_bbox_loss: 0.2592 - val_mrcnn_class_loss: 0.3223 - val_mrcnn_bbox_loss: 0.1608 - val_mrcnn_mask_loss: 0.2059\n"
     ]
    }
   ],
   "source": [
    "model.epoch = 84\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE,\n",
    "            epochs=EPOCHS,\n",
    "            layers=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from  12_instances_100-0.95.hdf5\n",
      "Evaluating 1 out of 1000 val examples\n",
      "Evaluating 101 out of 1000 val examples\n",
      "Evaluating 201 out of 1000 val examples\n",
      "Evaluating 301 out of 1000 val examples\n",
      "Evaluating 401 out of 1000 val examples\n",
      "Evaluating 501 out of 1000 val examples\n",
      "Evaluating 601 out of 1000 val examples\n",
      "Evaluating 701 out of 1000 val examples\n",
      "Evaluating 801 out of 1000 val examples\n",
      "Evaluating 901 out of 1000 val examples\n",
      "gt file: C:\\Users\\yliu60\\Documents\\GitHub\\Pixel-Embedding\\gt_json\\deeplabv3\\12\\shapes_val_small_12_[1, 2, 3].json\n",
      "loading annotations into memory...\n",
      "Done (t=0.18s)\n",
      "creating index...\n",
      "index created!\n",
      "processing json 1 in total 1\n",
      "Loading and preparing results...\n",
      "DONE (t=0.05s)\n",
      "creating index...\n",
      "index created!\n",
      "DONE (t=3.95s).\n",
      "DONE (t=2.94s).\n",
      "DONE (t=3.14s).\n",
      "DONE (t=3.33s).\n",
      "DONE (t=3.92s).\n",
      "DONE (t=2.91s).\n",
      "DONE (t=3.12s).\n",
      "DONE (t=3.34s).\n",
      "DONE (t=3.63s).\n",
      "DONE (t=3.63s).\n",
      "DONE (t=3.67s).\n",
      "DONE (t=3.64s).\n",
      "done! intermediate file cleaned!\n",
      "NMS threshold: 0.0\n",
      "0.2793 & 0.3362 & 0.3201 & 0.2904 & 0.6174 & 0.4809 & 0.1883 \\\\ \n",
      " \\hline\n",
      "Loading weights from  12_instances_100-0.95.hdf5\n",
      "Evaluating 1 out of 1000 val examples\n",
      "Evaluating 101 out of 1000 val examples\n",
      "Evaluating 201 out of 1000 val examples\n",
      "Evaluating 301 out of 1000 val examples\n",
      "Evaluating 401 out of 1000 val examples\n",
      "Evaluating 501 out of 1000 val examples\n",
      "Evaluating 601 out of 1000 val examples\n",
      "Evaluating 701 out of 1000 val examples\n",
      "Evaluating 801 out of 1000 val examples\n",
      "Evaluating 901 out of 1000 val examples\n",
      "gt file: C:\\Users\\yliu60\\Documents\\GitHub\\Pixel-Embedding\\gt_json\\deeplabv3\\12\\shapes_val_small_12_[1, 2, 3].json\n",
      "loading annotations into memory...\n",
      "Done (t=0.19s)\n",
      "creating index...\n",
      "index created!\n",
      "processing json 1 in total 1\n",
      "Loading and preparing results...\n",
      "DONE (t=0.07s)\n",
      "creating index...\n",
      "index created!\n",
      "DONE (t=4.93s).\n",
      "DONE (t=3.74s).\n",
      "DONE (t=3.89s).\n",
      "DONE (t=4.23s).\n",
      "DONE (t=4.88s).\n",
      "DONE (t=3.71s).\n",
      "DONE (t=3.90s).\n",
      "DONE (t=4.23s).\n",
      "DONE (t=4.54s).\n",
      "DONE (t=4.56s).\n",
      "DONE (t=4.60s).\n",
      "DONE (t=4.59s).\n",
      "done! intermediate file cleaned!\n",
      "NMS threshold: 0.1\n",
      "0.3564 & 0.4350 & 0.4068 & 0.3730 & 0.7247 & 0.6220 & 0.2562 \\\\ \n",
      " \\hline\n",
      "Loading weights from  12_instances_100-0.95.hdf5\n",
      "Evaluating 1 out of 1000 val examples\n",
      "Evaluating 101 out of 1000 val examples\n",
      "Evaluating 201 out of 1000 val examples\n",
      "Evaluating 301 out of 1000 val examples\n",
      "Evaluating 401 out of 1000 val examples\n",
      "Evaluating 501 out of 1000 val examples\n",
      "Evaluating 601 out of 1000 val examples\n",
      "Evaluating 701 out of 1000 val examples\n",
      "Evaluating 801 out of 1000 val examples\n",
      "Evaluating 901 out of 1000 val examples\n",
      "gt file: C:\\Users\\yliu60\\Documents\\GitHub\\Pixel-Embedding\\gt_json\\deeplabv3\\12\\shapes_val_small_12_[1, 2, 3].json\n",
      "loading annotations into memory...\n",
      "Done (t=0.18s)\n",
      "creating index...\n",
      "index created!\n",
      "processing json 1 in total 1\n",
      "Loading and preparing results...\n",
      "DONE (t=0.08s)\n",
      "creating index...\n",
      "index created!\n",
      "DONE (t=5.79s).\n",
      "DONE (t=4.42s).\n",
      "DONE (t=4.52s).\n",
      "DONE (t=4.92s).\n",
      "DONE (t=5.74s).\n",
      "DONE (t=4.41s).\n",
      "DONE (t=4.54s).\n",
      "DONE (t=4.95s).\n",
      "DONE (t=5.29s).\n",
      "DONE (t=5.26s).\n",
      "DONE (t=5.33s).\n",
      "DONE (t=5.30s).\n",
      "done! intermediate file cleaned!\n",
      "NMS threshold: 0.2\n",
      "0.4166 & 0.5138 & 0.4740 & 0.4385 & 0.7831 & 0.7232 & 0.3173 \\\\ \n",
      " \\hline\n",
      "Loading weights from  12_instances_100-0.95.hdf5\n",
      "Evaluating 1 out of 1000 val examples\n",
      "Evaluating 101 out of 1000 val examples\n",
      "Evaluating 201 out of 1000 val examples\n",
      "Evaluating 301 out of 1000 val examples\n",
      "Evaluating 401 out of 1000 val examples\n",
      "Evaluating 501 out of 1000 val examples\n",
      "Evaluating 601 out of 1000 val examples\n",
      "Evaluating 701 out of 1000 val examples\n",
      "Evaluating 801 out of 1000 val examples\n",
      "Evaluating 901 out of 1000 val examples\n",
      "gt file: C:\\Users\\yliu60\\Documents\\GitHub\\Pixel-Embedding\\gt_json\\deeplabv3\\12\\shapes_val_small_12_[1, 2, 3].json\n",
      "loading annotations into memory...\n",
      "Done (t=0.18s)\n",
      "creating index...\n",
      "index created!\n",
      "processing json 1 in total 1\n",
      "Loading and preparing results...\n",
      "DONE (t=0.09s)\n",
      "creating index...\n",
      "index created!\n",
      "DONE (t=6.42s).\n",
      "DONE (t=4.93s).\n",
      "DONE (t=5.06s).\n",
      "DONE (t=5.47s).\n",
      "DONE (t=6.28s).\n",
      "DONE (t=4.93s).\n",
      "DONE (t=5.06s).\n",
      "DONE (t=5.47s).\n",
      "DONE (t=5.84s).\n",
      "DONE (t=5.84s).\n",
      "DONE (t=5.89s).\n",
      "DONE (t=5.86s).\n",
      "done! intermediate file cleaned!\n",
      "NMS threshold: 0.30000000000000004\n",
      "0.4641 & 0.5827 & 0.5312 & 0.4887 & 0.8226 & 0.7678 & 0.3715 \\\\ \n",
      " \\hline\n",
      "Loading weights from  12_instances_100-0.95.hdf5\n",
      "Evaluating 1 out of 1000 val examples\n",
      "Evaluating 101 out of 1000 val examples\n",
      "Evaluating 201 out of 1000 val examples\n",
      "Evaluating 301 out of 1000 val examples\n",
      "Evaluating 401 out of 1000 val examples\n",
      "Evaluating 501 out of 1000 val examples\n",
      "Evaluating 601 out of 1000 val examples\n",
      "Evaluating 701 out of 1000 val examples\n",
      "Evaluating 801 out of 1000 val examples\n",
      "Evaluating 901 out of 1000 val examples\n",
      "gt file: C:\\Users\\yliu60\\Documents\\GitHub\\Pixel-Embedding\\gt_json\\deeplabv3\\12\\shapes_val_small_12_[1, 2, 3].json\n",
      "loading annotations into memory...\n",
      "Done (t=0.20s)\n",
      "creating index...\n",
      "index created!\n",
      "processing json 1 in total 1\n",
      "Loading and preparing results...\n",
      "DONE (t=0.10s)\n",
      "creating index...\n",
      "index created!\n",
      "DONE (t=7.30s).\n",
      "DONE (t=5.75s).\n",
      "DONE (t=6.03s).\n",
      "DONE (t=6.36s).\n",
      "DONE (t=7.36s).\n",
      "DONE (t=6.09s).\n",
      "DONE (t=5.86s).\n",
      "DONE (t=6.28s).\n",
      "DONE (t=6.89s).\n",
      "DONE (t=6.88s).\n",
      "DONE (t=6.29s).\n",
      "DONE (t=6.27s).\n",
      "done! intermediate file cleaned!\n",
      "NMS threshold: 0.4\n",
      "0.4978 & 0.6220 & 0.5690 & 0.5239 & 0.8485 & 0.7910 & 0.4114 \\\\ \n",
      " \\hline\n",
      "Loading weights from  12_instances_100-0.95.hdf5\n",
      "Evaluating 1 out of 1000 val examples\n",
      "Evaluating 101 out of 1000 val examples\n",
      "Evaluating 201 out of 1000 val examples\n",
      "Evaluating 301 out of 1000 val examples\n",
      "Evaluating 401 out of 1000 val examples\n",
      "Evaluating 501 out of 1000 val examples\n",
      "Evaluating 601 out of 1000 val examples\n",
      "Evaluating 701 out of 1000 val examples\n",
      "Evaluating 801 out of 1000 val examples\n",
      "Evaluating 901 out of 1000 val examples\n",
      "gt file: C:\\Users\\yliu60\\Documents\\GitHub\\Pixel-Embedding\\gt_json\\deeplabv3\\12\\shapes_val_small_12_[1, 2, 3].json\n",
      "loading annotations into memory...\n",
      "Done (t=0.19s)\n",
      "creating index...\n",
      "index created!\n",
      "processing json 1 in total 1\n",
      "Loading and preparing results...\n",
      "DONE (t=0.10s)\n",
      "creating index...\n",
      "index created!\n",
      "DONE (t=7.02s).\n",
      "DONE (t=5.50s).\n",
      "DONE (t=5.76s).\n",
      "DONE (t=6.03s).\n",
      "DONE (t=6.95s).\n",
      "DONE (t=5.49s).\n",
      "DONE (t=5.67s).\n",
      "DONE (t=6.02s).\n",
      "DONE (t=6.54s).\n",
      "DONE (t=6.45s).\n",
      "DONE (t=6.46s).\n",
      "DONE (t=6.49s).\n",
      "done! intermediate file cleaned!\n",
      "NMS threshold: 0.5\n",
      "0.5127 & 0.6416 & 0.5874 & 0.5399 & 0.8618 & 0.8019 & 0.4290 \\\\ \n",
      " \\hline\n",
      "Loading weights from  12_instances_100-0.95.hdf5\n",
      "Evaluating 1 out of 1000 val examples\n",
      "Evaluating 101 out of 1000 val examples\n",
      "Evaluating 201 out of 1000 val examples\n",
      "Evaluating 301 out of 1000 val examples\n",
      "Evaluating 401 out of 1000 val examples\n",
      "Evaluating 501 out of 1000 val examples\n",
      "Evaluating 601 out of 1000 val examples\n",
      "Evaluating 701 out of 1000 val examples\n",
      "Evaluating 801 out of 1000 val examples\n",
      "Evaluating 901 out of 1000 val examples\n",
      "gt file: C:\\Users\\yliu60\\Documents\\GitHub\\Pixel-Embedding\\gt_json\\deeplabv3\\12\\shapes_val_small_12_[1, 2, 3].json\n",
      "loading annotations into memory...\n",
      "Done (t=0.19s)\n",
      "creating index...\n",
      "index created!\n",
      "processing json 1 in total 1\n",
      "Loading and preparing results...\n",
      "DONE (t=0.10s)\n",
      "creating index...\n",
      "index created!\n",
      "DONE (t=7.16s).\n",
      "DONE (t=5.67s).\n",
      "DONE (t=5.83s).\n",
      "DONE (t=6.22s).\n",
      "DONE (t=7.10s).\n",
      "DONE (t=5.65s).\n",
      "DONE (t=5.80s).\n",
      "DONE (t=6.27s).\n",
      "DONE (t=6.61s).\n",
      "DONE (t=6.60s).\n",
      "DONE (t=6.65s).\n",
      "DONE (t=6.65s).\n",
      "done! intermediate file cleaned!\n",
      "NMS threshold: 0.6000000000000001\n",
      "0.5167 & 0.6506 & 0.5866 & 0.5472 & 0.8674 & 0.8070 & 0.4366 \\\\ \n",
      " \\hline\n",
      "Loading weights from  12_instances_100-0.95.hdf5\n",
      "Evaluating 1 out of 1000 val examples\n",
      "Evaluating 101 out of 1000 val examples\n",
      "Evaluating 201 out of 1000 val examples\n",
      "Evaluating 301 out of 1000 val examples\n",
      "Evaluating 401 out of 1000 val examples\n",
      "Evaluating 501 out of 1000 val examples\n",
      "Evaluating 601 out of 1000 val examples\n",
      "Evaluating 701 out of 1000 val examples\n",
      "Evaluating 801 out of 1000 val examples\n",
      "Evaluating 901 out of 1000 val examples\n",
      "gt file: C:\\Users\\yliu60\\Documents\\GitHub\\Pixel-Embedding\\gt_json\\deeplabv3\\12\\shapes_val_small_12_[1, 2, 3].json\n",
      "loading annotations into memory...\n",
      "Done (t=0.19s)\n",
      "creating index...\n",
      "index created!\n",
      "processing json 1 in total 1\n",
      "Loading and preparing results...\n",
      "DONE (t=0.11s)\n",
      "creating index...\n",
      "index created!\n",
      "DONE (t=7.45s).\n",
      "DONE (t=5.99s).\n",
      "DONE (t=6.12s).\n",
      "DONE (t=6.49s).\n",
      "DONE (t=7.43s).\n",
      "DONE (t=5.95s).\n",
      "DONE (t=6.13s).\n",
      "DONE (t=6.54s).\n",
      "DONE (t=6.96s).\n",
      "DONE (t=6.93s).\n",
      "DONE (t=6.94s).\n",
      "DONE (t=6.96s).\n",
      "done! intermediate file cleaned!\n",
      "NMS threshold: 0.7000000000000001\n",
      "0.5203 & 0.6570 & 0.5926 & 0.5533 & 0.8722 & 0.8110 & 0.4424 \\\\ \n",
      " \\hline\n",
      "Loading weights from  12_instances_100-0.95.hdf5\n",
      "Evaluating 1 out of 1000 val examples\n",
      "Evaluating 101 out of 1000 val examples\n",
      "Evaluating 201 out of 1000 val examples\n",
      "Evaluating 301 out of 1000 val examples\n",
      "Evaluating 401 out of 1000 val examples\n",
      "Evaluating 501 out of 1000 val examples\n",
      "Evaluating 601 out of 1000 val examples\n",
      "Evaluating 701 out of 1000 val examples\n",
      "Evaluating 801 out of 1000 val examples\n",
      "Evaluating 901 out of 1000 val examples\n",
      "gt file: C:\\Users\\yliu60\\Documents\\GitHub\\Pixel-Embedding\\gt_json\\deeplabv3\\12\\shapes_val_small_12_[1, 2, 3].json\n",
      "loading annotations into memory...\n",
      "Done (t=0.18s)\n",
      "creating index...\n",
      "index created!\n",
      "processing json 1 in total 1\n",
      "Loading and preparing results...\n",
      "DONE (t=0.13s)\n",
      "creating index...\n",
      "index created!\n",
      "DONE (t=8.41s).\n",
      "DONE (t=6.91s).\n",
      "DONE (t=6.97s).\n",
      "DONE (t=7.39s).\n",
      "DONE (t=8.27s).\n",
      "DONE (t=6.82s).\n",
      "DONE (t=7.02s).\n",
      "DONE (t=7.42s).\n",
      "DONE (t=7.88s).\n",
      "DONE (t=7.83s).\n",
      "DONE (t=7.93s).\n",
      "DONE (t=7.88s).\n",
      "done! intermediate file cleaned!\n",
      "NMS threshold: 0.8\n",
      "0.5142 & 0.6568 & 0.5846 & 0.5620 & 0.8762 & 0.8167 & 0.4504 \\\\ \n",
      " \\hline\n",
      "Loading weights from  12_instances_100-0.95.hdf5\n",
      "Evaluating 1 out of 1000 val examples\n",
      "Evaluating 101 out of 1000 val examples\n",
      "Evaluating 201 out of 1000 val examples\n",
      "Evaluating 301 out of 1000 val examples\n",
      "Evaluating 401 out of 1000 val examples\n",
      "Evaluating 501 out of 1000 val examples\n",
      "Evaluating 601 out of 1000 val examples\n",
      "Evaluating 701 out of 1000 val examples\n",
      "Evaluating 801 out of 1000 val examples\n",
      "Evaluating 901 out of 1000 val examples\n",
      "gt file: C:\\Users\\yliu60\\Documents\\GitHub\\Pixel-Embedding\\gt_json\\deeplabv3\\12\\shapes_val_small_12_[1, 2, 3].json\n",
      "loading annotations into memory...\n",
      "Done (t=2.56s)\n",
      "creating index...\n",
      "index created!\n",
      "processing json 1 in total 1\n",
      "Loading and preparing results...\n",
      "DONE (t=0.24s)\n",
      "creating index...\n",
      "index created!\n",
      "DONE (t=13.90s).\n",
      "DONE (t=12.33s).\n",
      "DONE (t=12.39s).\n",
      "DONE (t=12.83s).\n",
      "DONE (t=13.82s).\n",
      "DONE (t=12.32s).\n",
      "DONE (t=12.47s).\n",
      "DONE (t=12.78s).\n",
      "DONE (t=13.34s).\n",
      "DONE (t=13.26s).\n",
      "DONE (t=13.36s).\n",
      "DONE (t=13.42s).\n",
      "done! intermediate file cleaned!\n",
      "NMS threshold: 0.9\n",
      "0.4022 & 0.5253 & 0.4450 & 0.5856 & 0.8913 & 0.8326 & 0.4702 \\\\ \n",
      " \\hline\n",
      "Loading weights from  12_instances_100-0.95.hdf5\n",
      "Evaluating 1 out of 1000 val examples\n",
      "Evaluating 101 out of 1000 val examples\n",
      "Evaluating 201 out of 1000 val examples\n",
      "Evaluating 301 out of 1000 val examples\n",
      "Evaluating 401 out of 1000 val examples\n",
      "Evaluating 501 out of 1000 val examples\n",
      "Evaluating 601 out of 1000 val examples\n",
      "Evaluating 701 out of 1000 val examples\n",
      "Evaluating 801 out of 1000 val examples\n",
      "Evaluating 901 out of 1000 val examples\n",
      "gt file: C:\\Users\\yliu60\\Documents\\GitHub\\Pixel-Embedding\\gt_json\\deeplabv3\\12\\shapes_val_small_12_[1, 2, 3].json\n",
      "loading annotations into memory...\n",
      "Done (t=0.18s)\n",
      "creating index...\n",
      "index created!\n",
      "processing json 1 in total 1\n",
      "Loading and preparing results...\n",
      "DONE (t=0.43s)\n",
      "creating index...\n",
      "index created!\n",
      "DONE (t=24.65s).\n",
      "DONE (t=22.95s).\n",
      "DONE (t=22.79s).\n",
      "DONE (t=23.44s).\n",
      "DONE (t=24.38s).\n",
      "DONE (t=22.83s).\n",
      "DONE (t=23.07s).\n",
      "DONE (t=23.31s).\n",
      "DONE (t=23.74s).\n",
      "DONE (t=23.83s).\n",
      "DONE (t=23.86s).\n",
      "DONE (t=23.99s).\n",
      "done! intermediate file cleaned!\n",
      "NMS threshold: 1.0\n",
      "0.2184 & 0.2883 & 0.2349 & 0.5782 & 0.8947 & 0.8266 & 0.4572 \\\\ \n",
      " \\hline\n"
     ]
    }
   ],
   "source": [
    "for i in np.linspace(0, 1, 11):\n",
    "    inference_config.RPN_NMS_THRESHOLD = 1.0\n",
    "    inference_config.DETECTION_NMS_THRESHOLD = np.float32(i)\n",
    "    model = modellib.MaskRCNN(mode=\"inference\", \n",
    "                              config=inference_config,\n",
    "                              model_dir=MODEL_DIR)\n",
    "\n",
    "    current_epoch = 100\n",
    "\n",
    "    # Load trained weights\n",
    "    model_path = '12_instances_100-0.95.hdf5'\n",
    "    print(\"Loading weights from \", model_path)\n",
    "    model.load_weights(model_path, by_name=True)\n",
    "\n",
    "    dt_filename = 'shapes.json'\n",
    "    result_list = get_mrcnn_result_list(model, config)\n",
    "\n",
    "    with open(os.path.join(config.DT_DIR, dt_filename), 'w') as outfile:\n",
    "        json.dump(result_list, outfile)\n",
    "\n",
    "    config.GT_JSON_DIR = 'C:\\\\Users\\\\yliu60\\\\Documents\\\\GitHub\\\\Pixel-Embedding\\\\gt_json\\\\deeplabv3\\\\12\\\\shapes_val_small_12_[1, 2, 3].json'\n",
    "\n",
    "    args = params_lib.Args()\n",
    "\n",
    "    args.num_shape_per_class = None\n",
    "    args.dt_dir              = config.DT_DIR\n",
    "    args.gt_dir              = config.GT_JSON_DIR\n",
    "    args.maxProp             = int(1000)\n",
    "    args.outputFile          = 'output'\n",
    "\n",
    "    metrics = batchEval.main(args)\n",
    "\n",
    "    print(\"NMS threshold: {}\".format(i))\n",
    "    ap            = metrics['both'].ap\n",
    "    ap50          = metrics['both'].ap_05\n",
    "    ap75          = metrics['both'].ap_075\n",
    "    ar100         = metrics['both'].ar100\n",
    "    ar_none       = metrics['both'].ar_none\n",
    "    ar_partial    = metrics['both'].ar_partial\n",
    "    ar_heavy      = metrics['both'].ar_heavy\n",
    "    string_format = \"{:.4f} & {:.4f} & {:.4f} & {:.4f} & {:.4f} & {:.4f} & {:.4f} \\\\\\\\ \\n \\\\hline\"\n",
    "    print(string_format.format(\n",
    "        ap, ap50, ap75, ar100, ar_none, ar_partial, ar_heavy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(4):\n",
    "    image_id = random.choice(dataset_val.image_ids)\n",
    "    print('image_id = {}'.format(image_id))\n",
    "    original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "        modellib.load_image_gt(dataset_val, inference_config, \n",
    "                               image_id, use_mini_mask=False)\n",
    "\n",
    "    log(\"original_image\", original_image)\n",
    "    log(\"image_meta\", image_meta)\n",
    "    log(\"gt_class_id\", gt_class_id)\n",
    "    log(\"gt_bbox\", gt_bbox)\n",
    "    log(\"gt_mask\", gt_mask)\n",
    "\n",
    "    visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
    "                                dataset_val.class_names, figsize=(8, 8))\n",
    "\n",
    "    results = model.detect([original_image], verbose=0)\n",
    "\n",
    "    r = results[0]\n",
    "    visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
    "                                dataset_val.class_names, r['scores'], ax=get_ax())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
